{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston, load_breast_cancer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kfold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=19)\n",
    "kfold.get_n_splits(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standadization\n",
    "std_scale = preprocessing.StandardScaler().fit(X)\n",
    "X = std_scale.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparar os resultados dos seguintes algoritmos: DecisionTree, RandomForest e Gradient Boosting\n",
    "#### Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =  [0.1, 0.05, 0.01]\n",
    "n_estimators = [50, 100, 200]\n",
    "max_depth = [3, 5, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Random Forest\n",
      "3.452894799895121\n",
      "2.4528569883897884\n",
      "\n",
      "# Gradiente Boosting\n",
      "3.690215043177053\n",
      "2.7070969185016533\n",
      "\n",
      "# DecisionTreeRegressor\n",
      "4.429473517786514\n",
      "2.913828382838284\n"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "rfr_rmse = []\n",
    "rfr_mae = []\n",
    "\n",
    "gbr_rmse = []\n",
    "gbr_mae = []\n",
    "\n",
    "dtr_rmse = []\n",
    "dtr_mae = []\n",
    "\n",
    "modelos_gbr = dict()\n",
    "for train_index, test_index in kfold.split(X,y):\n",
    "    for estimator in n_estimators:\n",
    "        for depth in max_depth:\n",
    "            # Random Forest\n",
    "            randomForestRegressor = RandomForestRegressor(max_depth=depth, random_state=SEED, n_estimators=estimator, n_jobs=-1)\n",
    "            randomForestRegressor.fit(X[train_index], y[train_index])\n",
    "            y_pred = randomForestRegressor.predict(X[test_index])\n",
    "            rfr_rmse.append(np.sqrt(metrics.mean_squared_error(y[test_index], y_pred)))\n",
    "            rfr_mae.append(metrics.mean_absolute_error(y[test_index], y_pred))\n",
    "            # Gradiente Boosting\n",
    "            for rate in learning_rate:\n",
    "                gbr = GradientBoostingRegressor(learning_rate=rate, n_estimators=estimator,random_state=SEED)\n",
    "                gbr.fit(X[train_index], y[train_index])\n",
    "                y_pred = gbr.predict(X[test_index])\n",
    "                gbr_rmse.append(np.sqrt(metrics.mean_squared_error(y[test_index], y_pred)))\n",
    "                gbr_mae.append(metrics.mean_absolute_error(y[test_index], y_pred))\n",
    "print(\"# Random Forest\")\n",
    "print(np.mean(rfr_rmse))\n",
    "print(np.mean(rfr_mae))\n",
    "\n",
    "print(\"\\n# Gradiente Boosting\")\n",
    "print(np.mean(gbr_rmse))\n",
    "print(np.mean(gbr_mae))\n",
    "\n",
    "# DecisionTreeRegressor\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf = DecisionTreeRegressor(random_state=SEED)\n",
    "    clf.fit(X_train, y_train);\n",
    "    y_pred_gd = clf.predict(X_test)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test,y_pred_gd))\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred_gd)\n",
    "    dtr_rmse.append(rmse)\n",
    "    dtr_mae.append(mae)\n",
    "print(\"\\n# DecisionTreeRegressor\")\n",
    "print(np.mean(dtr_rmse))\n",
    "print(np.mean(dtr_mae)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.06645591e-02, 1.82781632e-04, 3.41046471e-03, 2.34851532e-04,\n",
       "       1.19450984e-02, 4.14251230e-01, 9.35151803e-03, 4.79532318e-02,\n",
       "       3.41338613e-03, 9.63349633e-03, 8.56043283e-03, 3.81017192e-03,\n",
       "       4.46588778e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o melhor modelo foi o randomForestRegressor\n",
    "randomForestRegressor = RandomForestRegressor(max_depth=5, random_state=SEED, n_estimators=100, n_jobs=-1)\n",
    "randomForestRegressor.fit(X[train_index], y[train_index])\n",
    "randomForestRegressor.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_breast_cancer(return_X_y=True) # Dataset: breast cancer wisconsin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(X)\n",
    "X = std_scale.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# DecisionTreeClassifier\n",
      "0.24838620074695766\n",
      "0.06334420121099207\n",
      "\n",
      "# RandomForestClassifier\n",
      "0.20894175200325343\n",
      "0.04528454863806518\n",
      "\n",
      "# GradientBoostingClassifier\n",
      "0.2503443717222367\n",
      "0.06520841599245575\n"
     ]
    }
   ],
   "source": [
    "dtc_rmse = []\n",
    "dtc_mae = []\n",
    "\n",
    "rfc_rmse = []\n",
    "rfc_mae = []\n",
    "\n",
    "gbc_rmse = []\n",
    "gbc_mae = []\n",
    "# DecisionTreeClassifier\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    dtc = DecisionTreeClassifier(random_state=SEED)\n",
    "    dtc.fit(X[train_index], y[train_index])\n",
    "    y_pred = dtc.predict(X[test_index])\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y[test_index],y_pred))\n",
    "    mae = metrics.mean_absolute_error(y[test_index],y_pred)\n",
    "    dtc_rmse.append(rmse)\n",
    "    dtc_mae.append(mae)\n",
    "    for estimator in n_estimators:\n",
    "        for depth in max_depth:\n",
    "            # RandomForestClassifier\n",
    "            rfc = RandomForestClassifier(n_estimators=estimator, max_depth=depth, random_state=SEED, n_jobs=-1)\n",
    "            rfc.fit(X[train_index], y[train_index])\n",
    "            y_pred = rfc.predict(X[test_index])\n",
    "            rmse = np.sqrt(metrics.mean_squared_error(y[test_index],y_pred))\n",
    "            mae = metrics.mean_absolute_error(y[test_index],y_pred)\n",
    "            rfc_rmse.append(rmse)\n",
    "            rfc_mae.append(mae)\n",
    "            for rate in learning_rate:\n",
    "                # GradientBoostingClassifier\n",
    "                gbc = GradientBoostingClassifier(learning_rate=rate, n_estimators=estimator, max_depth=depth, random_state=SEED)\n",
    "                gbc.fit(X[train_index], y[train_index])\n",
    "                y_pred = gbc.predict(X[test_index])\n",
    "                rmse = np.sqrt(metrics.mean_squared_error(y[test_index],y_pred))\n",
    "                mae = metrics.mean_absolute_error(y[test_index],y_pred)\n",
    "                gbc_rmse.append(rmse)\n",
    "                gbc_mae.append(mae)\n",
    "print(\"# DecisionTreeClassifier\")\n",
    "print(np.mean(dtc_rmse))\n",
    "print(np.mean(dtc_mae))\n",
    "print(\"\\n# RandomForestClassifier\")\n",
    "print(np.mean(rfc_rmse))\n",
    "print(np.mean(rfc_mae))\n",
    "print(\"\\n# GradientBoostingClassifier\")\n",
    "print(np.mean(gbc_rmse))\n",
    "print(np.mean(gbc_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03398677, 0.01510743, 0.08334399, 0.05962119, 0.0042937 ,\n",
       "       0.01100051, 0.05899307, 0.05891376, 0.00353153, 0.00390844,\n",
       "       0.0211925 , 0.00214323, 0.01178205, 0.03952919, 0.00244982,\n",
       "       0.00396661, 0.00458008, 0.00238788, 0.00318195, 0.00384533,\n",
       "       0.07456312, 0.01939381, 0.10111154, 0.16413222, 0.00822359,\n",
       "       0.01232358, 0.03576346, 0.14167411, 0.0091443 , 0.00591121])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o melhor modelo foi o randomForestClassifier\n",
    "randomForestClassifier = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=SEED, n_jobs=-1)\n",
    "randomForestClassifier.fit(X[train_index], y[train_index])\n",
    "randomForestClassifier.feature_importances_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
